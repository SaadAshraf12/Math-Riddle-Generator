{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10980215,"sourceType":"datasetVersion","datasetId":6833119}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets peft torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:12:03.624930Z","iopub.execute_input":"2025-03-10T15:12:03.625244Z","iopub.status.idle":"2025-03-10T15:12:07.939848Z","shell.execute_reply.started":"2025-03-10T15:12:03.625213Z","shell.execute_reply":"2025-03-10T15:12:07.938734Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.2.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.remove('/kaggle/working/fine-tuned-QA-tinyllama-1.1B')\nos.remove('/kaggle/working/outputs')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:06:09.601020Z","iopub.execute_input":"2025-03-10T15:06:09.601307Z","iopub.status.idle":"2025-03-10T15:06:09.613401Z","shell.execute_reply.started":"2025-03-10T15:06:09.601285Z","shell.execute_reply":"2025-03-10T15:06:09.612365Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-3404aa22adc3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/working/fine-tuned-QA-tinyllama-1.1B'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/working/outputs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/fine-tuned-QA-tinyllama-1.1B'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/working/fine-tuned-QA-tinyllama-1.1B'","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"model_ref = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:12:30.373148Z","iopub.execute_input":"2025-03-10T15:12:30.373477Z","iopub.status.idle":"2025-03-10T15:12:30.377211Z","shell.execute_reply.started":"2025-03-10T15:12:30.373446Z","shell.execute_reply":"2025-03-10T15:12:30.376222Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# qa_data = [\n#     {\"question\": \"What was the revenue for AlphaTech Inc. in Q3?\", \"answer\": \"$80M\"},\n#     {\"question\": \"How many new customers did AlphaTech acquire in Q2?\", \"answer\": \"25,000 new users\"},\n#     {\"question\": \"Which quarter did AlphaTech enter the Asian market?\", \"answer\": \"Q3\"},\n#     {\"question\": \"What was the net profit of AlphaTech in Q4?\", \"answer\": \"$15M\"},\n#     {\"question\": \"What investment did AlphaTech make in Q1?\", \"answer\": \"Invested $5M in AI research.\"},\n#     {\"question\": \"What major challenge did AlphaTech face in Q3?\", \"answer\": \"Rising competition.\"},\n#     {\"question\": \"Which region did AlphaTech expand to in Q4?\", \"answer\": \"Latin America.\"},\n#     {\"question\": \"What was the main regulatory challenge faced by AlphaTech?\", \"answer\": \"Regulatory compliance challenges in Q4.\"}]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T14:17:38.614672Z","iopub.execute_input":"2025-03-10T14:17:38.614912Z","iopub.status.idle":"2025-03-10T14:17:38.618776Z","shell.execute_reply.started":"2025-03-10T14:17:38.614892Z","shell.execute_reply":"2025-03-10T14:17:38.618034Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"qa_data = [\n    {\"question\": \"What number becomes zero when you subtract 15 from half of it?\", \"answer\": \"30\"},\n    {\"question\": \"What three positive numbers give the same answer when multiplied and added together?\", \"answer\": \"1, 2, and 3\"},\n    {\"question\": \"I am a number. Divide me by 3, then add 5, and you get 11. What number am I?\", \"answer\": \"18\"},\n    {\"question\": \"I am a number less than 50. If you double me and subtract 10, you get 30. What number am I?\", \"answer\": \"20\"},\n    {\"question\": \"A farmer has 17 sheep, and all but 9 run away. How many are left?\", \"answer\": \"9\"},\n    {\"question\": \"The sum of two numbers is 16, and their difference is 4. What are the numbers?\", \"answer\": \"10 and 6\"},\n    {\"question\": \"Double a number and subtract 8 to get 10. What number is it?\", \"answer\": \"9\"},\n    {\"question\": \"A clock shows 3:15. What is the angle between the hour and the minute hand?\", \"answer\": \"7.5 degrees\"},\n    {\"question\": \"What number do you get if you divide 30 by half and add 10?\", \"answer\": \"70\"},\n    {\"question\": \"Take me and double my value. Add 8, divide by 4, and you get 5. What number am I?\", \"answer\": \"6\"},\n    {\"question\": \"A box contains 12 apples. You take away 5. How many do you have?\", \"answer\": \"5 (You took them!)\"},\n    {\"question\": \"If five cats catch five mice in five minutes, how many cats are needed to catch 100 mice in 100 minutes?\", \"answer\": \"5 cats\"},\n    {\"question\": \"The sum of three consecutive even numbers is 54. What are the numbers?\", \"answer\": \"16, 18, 20\"},\n    {\"question\": \"I am a two-digit number. My tens digit is 3 more than my ones digit. What number am I?\", \"answer\": \"41\"},\n    {\"question\": \"I am thinking of a number. When I add 10 to it and then divide by 2, I get 12. What number am I?\", \"answer\": \"14\"}\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:12:32.566454Z","iopub.execute_input":"2025-03-10T15:12:32.566802Z","iopub.status.idle":"2025-03-10T15:12:32.572161Z","shell.execute_reply.started":"2025-03-10T15:12:32.566773Z","shell.execute_reply":"2025-03-10T15:12:32.571130Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom peft import get_peft_model, LoraConfig, TaskType\nfrom datasets import Dataset\nfrom transformers import TrainingArguments, Trainer\nimport gc\n\n\n# Define the model name\nmodel_name = model_ref\n\n# Load pre-trained model & tokenizer\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Move model to GPU if available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:12:36.035502Z","iopub.execute_input":"2025-03-10T15:12:36.035907Z","iopub.status.idle":"2025-03-10T15:13:17.134373Z","shell.execute_reply.started":"2025-03-10T15:12:36.035873Z","shell.execute_reply":"2025-03-10T15:13:17.133657Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8c2ff68e410421681b97d72548462b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8a40d52d7ab4cc2a6ac4675675594cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af076aa4ece344c28f03d7ebc980d4a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0853c535e07454c87a860b3e7e070e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97d5ed36a4cd4afbb7a1a59d19048784"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1ecab74644d4eb0a3a8e9da2730dd71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"239948e530fb4ebbb578ea0d565d4502"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"def format_qa(example):\n    return {\n        \"text\": f\"Question: {example['question']} Answer: {example['answer']}\"\n    }\n\nqa_dataset = Dataset.from_list(qa_data)\nformatted_dataset = qa_dataset.map(format_qa)\n\n# Tokenization\ndef preprocess_function(examples):\n    inputs = tokenizer(\n        examples['text'],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=512\n    )\n\n    # Labels should be a shifted version of input_ids for causal LM training\n    inputs[\"labels\"] = inputs[\"input_ids\"].copy()\n    return inputs\n\n# Apply tokenization\ntokenized_qa_dataset = formatted_dataset.map(preprocess_function, batched=True)\n\n\n# Define LoRA configuration\nlora_config = LoraConfig(\n    task_type=TaskType.CAUSAL_LM,\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n)\n\n# Wrap model with LoRA\nmodel = get_peft_model(model, lora_config)\n\n\n# Set Training Arguments\n\ntraining_args = TrainingArguments(\n    per_device_train_batch_size=5,  # Adjusted for GPU memory limitations\n    gradient_accumulation_steps=3,  # To simulate a larger batch size\n    warmup_steps=100,\n    max_steps=3,#Number of epochs\n    learning_rate=2e-4,\n    fp16=True,  # Enable mixed precision training\n    logging_steps=10,\n    output_dir=\"outputs\",\n    report_to=\"none\",\n    remove_unused_columns=False,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:13:20.800217Z","iopub.execute_input":"2025-03-10T15:13:20.800887Z","iopub.status.idle":"2025-03-10T15:13:21.009093Z","shell.execute_reply.started":"2025-03-10T15:13:20.800854Z","shell.execute_reply":"2025-03-10T15:13:21.008133Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/15 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fe9eed13c2846e7a4eace78ab782171"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/15 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4448fc4b15d4fe39b515052cdaba9bd"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Move model to CPU to free memory before training\nmodel = model.to(\"cpu\")\n\n# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_qa_dataset,\n)\n\n# Free up memory before training\n\ngc.collect()  # Garbage collection\ntorch.cuda.empty_cache()  # Clears CUDA cache\nprint(\"GPU clache cleared\")\n\n# Optimize model with torch.compile (improves execution speed)\nmodel = torch.compile(model)\n\n# Move model back to GPU for training\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(device)\n\n# Start training\ntrainer.train()\n\n# Save the fine tuned model\nmodel.save_pretrained(\"fine-tuned-QA-tinyllama-1.1B\")\ntokenizer.save_pretrained(\"fine-tuned-QA-tinyllama-1.1B\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:13:23.000158Z","iopub.execute_input":"2025-03-10T15:13:23.000476Z","iopub.status.idle":"2025-03-10T15:13:47.992104Z","shell.execute_reply.started":"2025-03-10T15:13:23.000448Z","shell.execute_reply":"2025-03-10T15:13:47.991363Z"}},"outputs":[{"name":"stdout","text":"GPU clache cleared\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3/3 00:11, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"('fine-tuned-QA-tinyllama-1.1B/tokenizer_config.json',\n 'fine-tuned-QA-tinyllama-1.1B/special_tokens_map.json',\n 'fine-tuned-QA-tinyllama-1.1B/tokenizer.model',\n 'fine-tuned-QA-tinyllama-1.1B/added_tokens.json',\n 'fine-tuned-QA-tinyllama-1.1B/tokenizer.json')"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Load the fine-tuned model\nmodel_path = \"fine-tuned-QA-tinyllama-1.1B\"\nmodel = AutoModelForCausalLM.from_pretrained(model_path)\ntokenizer = AutoTokenizer.from_pretrained(model_path)\n\n# Move model to GPU if available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel.to(device)\n\ndef generate_answer(question, max_length=50):\n    prompt = f\"Question: {question} Answer:\"\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n\n    with torch.no_grad():\n        output = model.generate(**inputs, max_length=max_length, temperature=0.7, top_k=50, top_p=0.9)\n\n    return tokenizer.decode(output[0], skip_special_tokens=True)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:13:53.145382Z","iopub.execute_input":"2025-03-10T15:13:53.145743Z","iopub.status.idle":"2025-03-10T15:13:56.875168Z","shell.execute_reply.started":"2025-03-10T15:13:53.145714Z","shell.execute_reply":"2025-03-10T15:13:56.874166Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Example test cases - Known questions\ntest_questions = [\n    \"I am a two-digit number. My tens digit is 3 more than my ones digit. What number am I?\"\n]\n\nfor q in test_questions:\n    print(f\"Q: {q}\")\n    print(f\"A: {generate_answer(q)}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:14:16.025036Z","iopub.execute_input":"2025-03-10T15:14:16.025333Z","iopub.status.idle":"2025-03-10T15:14:16.277881Z","shell.execute_reply.started":"2025-03-10T15:14:16.025309Z","shell.execute_reply":"2025-03-10T15:14:16.277143Z"}},"outputs":[{"name":"stdout","text":"Q: I am a two-digit number. My tens digit is 3 more than my ones digit. What number am I?\nA: Question: I am a two-digit number. My tens digit is 3 more than my ones digit. What number am I? Answer: The number is 123.\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}